{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UCB方策**によるバンディットのアルゴリズムを考えていきます．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は確率バンディットで**UCB方策**を考えていきます，\n",
    "\n",
    "UCB方策とは簡潔に説明すると, **選択数が少ないアーム**は**真の報酬の期待値**を予測するのが難しいので少ないアームを優先的に引くために考えられたアルゴリズムです．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### まずはUCB方策の式を見ていきましょう．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar u_{i}(t) = \\hat u_{i}(t) + \\sqrt{\\frac{logt}{N_{i}(t)}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\hat u_{i}(t)$** は $t$ 回目までに推定されたアームiの報酬の期待値で, **$N_{i}(t)$** は$t$ 回目までにアームiが選ばれた回数です．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### この式の意味は**期待値が低いアーム**でも選択回数が低いなら, 積極的に引くということです."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **早速アルゴリズムに入っていきます．**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#今回はアームが4つの場合を想定します，\n",
    "class UCB_bandit:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        N -> armがそれぞれ選ばれた回数\n",
    "        rewards -> armのそれぞれの総報酬\n",
    "        '''\n",
    "        self.p = [0.1, 0.3, 0.5, 0.8] #最適なアームのインデックスは3\n",
    "        self.N = np.zeros(len(self.p))\n",
    "        self.rewards = np.zeros(len(self.p))\n",
    "\n",
    "\n",
    "    def choose_action(self,N: int,t: int):\n",
    "        #1回も選ばれてないアームをなくす．\n",
    "        if t in [0,1,2,3]:\n",
    "            return t\n",
    "\n",
    "        rewards = np.zeros(len(self.p))\n",
    "        for i in range(len(self.p)):\n",
    "            reward = self.rewards[i]/self.N[i] + 0.01 * np.sqrt(np.log(t) / (2*self.N[i]))\n",
    "            np.append(rewards[i],reward)\n",
    "        max_index = np.where(rewards == rewards.max())\n",
    "        index = np.random.choice(max_index[0])\n",
    "\n",
    "    \n",
    "        return index\n",
    "            \n",
    "\n",
    "    def reward(self,index: int):\n",
    "\n",
    "        return np.random.binomial(1,self.p[index],1)\n",
    "\n",
    "    \n",
    "    def update(self,index,reward):\n",
    "        self.rewards[index] += reward\n",
    "        self.N[index] += 1\n",
    "\n",
    "    def simulate(self,T):\n",
    "        for i in tqdm(range(T)):\n",
    "            arm = self.choose_action(self.N,i)\n",
    "            \n",
    "            reward = self.reward(arm)\n",
    "\n",
    "            self.update(arm,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 11418.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0が選ばれた回数:24923.0回, 1が選ばれた回数:25081.0回, 2が選ばれた回数:24963.0回, 3が選ばれた回数:25033.0回\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent = UCB_bandit()\n",
    "agent.simulate(100000)\n",
    "print(f'0が選ばれた回数:{agent.N[0]}回, 1が選ばれた回数:{agent.N[1]}回, 2が選ばれた回数:{agent.N[2]}回, 3が選ばれた回数:{agent.N[3]}回')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2497.  7559. 12456. 20159.] [24923. 25081. 24963. 25033.]\n"
     ]
    }
   ],
   "source": [
    "print(agent.rewards,agent.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 6329.11it/s]\n"
     ]
    }
   ],
   "source": [
    "agent.simulate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2498.  7564. 12462. 20168.] [24931. 25094. 24980. 25045.]\n"
     ]
    }
   ],
   "source": [
    "print(agent.rewards,agent.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syumi-note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf02f90440595f5968a48e039387c923c9e6f6584bb1d7920e7063fafb8317aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

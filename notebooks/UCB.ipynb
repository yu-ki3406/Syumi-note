{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UCB方策**によるバンディットのアルゴリズムを考えていきます．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は確率バンディットで**UCB方策**を考えていきます，\n",
    "\n",
    "UCB方策とは簡潔に説明すると, **選択数が少ないアーム**は**真の報酬の期待値**を予測するのが難しいので少ないアームを優先的に引くために考えられたアルゴリズムです．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### まずはUCB方策の式を見ていきましょう．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar u_{i}(t) = \\hat u_{i}(t) + \\sqrt{\\frac{logt}{N_{i}(t)}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\hat u_{i}(t)$** は $t$ 回目までに推定されたアームiの報酬の期待値で, **$N_{i}(t)$** は$t$ 回目までにアームiが選ばれた回数です．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### この式の意味は**期待値が低いアーム**でも選択回数が低いなら, 積極的に引くということです."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **早速アルゴリズムに入っていきます．**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#今回はアームが4つの場合を想定します，\n",
    "class UCB_bandit:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        p -> それぞれ報酬が発生する確率\n",
    "        alpha,beta -> ベータ分布の確率\n",
    "        m -> それぞれの報酬が出た回数\n",
    "        n -> ぞれぞれが試行された数\n",
    "        '''\n",
    "        self.p = [0.1, 0.3, 0.5, 0.8] #最適なアームのインデックスは3\n",
    "        self.n = np.zeros(len(self.p))\n",
    "\n",
    "\n",
    "    def choose_action(self,m: int,n: int):\n",
    "        \n",
    "        best_index = None\n",
    "        prev_sample = 0\n",
    "        for i in range(len(self.p)):\n",
    "            sample = np.random.beta(self.alpha + m[i], self.beta + n[i] - m[i], 1)\n",
    "            if best_index == None:\n",
    "                best_index = i\n",
    "                prev_sample = sample\n",
    "                continue\n",
    "\n",
    "            if sample > prev_sample:\n",
    "                best_index = i\n",
    "                prev_sample = sample\n",
    "\n",
    "        return best_index\n",
    "\n",
    "    def reward(self,index: int):\n",
    "        return np.random.binomial(1,self.p[index],1)\n",
    "\n",
    "    \n",
    "    def update(self,index,reward):\n",
    "        self.m[index] += reward\n",
    "        self.n[index] += 1\n",
    "\n",
    "    def simulate(self,N):\n",
    "        for i in range(N):\n",
    "            arm = self.choose_action(self.m,self.n)\n",
    "            reward = self.reward(arm)\n",
    "            self.update(arm,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#今回はアームが4つの場合を想定します，\n",
    "class UCB_bandit:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        p -> それぞれ報酬が発生する確率\n",
    "        alpha,beta -> ベータ分布の確率\n",
    "        m -> それぞれの報酬が出た回数\n",
    "        n -> ぞれぞれが試行された数\n",
    "        '''\n",
    "        self.p = [0.1, 0.3, 0.5, 0.8] #最適なアームのインデックスは3\n",
    "        self.N = np.zeros(len(self.p))\n",
    "        self.rewards = np.zeros(len(self.p))\n",
    "\n",
    "\n",
    "    def choose_action(self,N: int,t: int):\n",
    "        #1回も選ばれてないアームをなくす．\n",
    "        if t in [0,1,2,3]:\n",
    "            return t\n",
    "\n",
    "        rewards = np.zeros(len(self.p))\n",
    "        for i in range(len(self.p)):\n",
    "            reward = self.rewards[i]/self.N[i] + np.sqrt(np.log(t) / 2 * self.N[i])\n",
    "            np.append(rewards[i],reward)\n",
    "        max_index = np.where(rewards == rewards.max())\n",
    "        index = np.random.choice(max_index[0])\n",
    "\n",
    "\n",
    "        return index\n",
    "            \n",
    "\n",
    "    def reward(self,index: int):\n",
    "\n",
    "        return np.random.binomial(1,self.p[index],1)\n",
    "\n",
    "    \n",
    "    def update(self,index,reward):\n",
    "        self.rewards[index] += reward\n",
    "        self.N[index] += 1\n",
    "\n",
    "    def simulate(self,T):\n",
    "        for i in tqdm(range(T)):\n",
    "            arm = self.choose_action(self.N,i)\n",
    "            reward = self.reward(arm)\n",
    "            self.update(arm,reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 10069.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0が選ばれた回数:221.0回, 1が選ばれた回数:253.0回, 2が選ばれた回数:255.0回, 3が選ばれた回数:271.0回\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agent = UCB_bandit()\n",
    "agent.simulate(1000)\n",
    "print(f'0が選ばれた回数:{agent.N[0]}回, 1が選ばれた回数:{agent.N[1]}回, 2が選ばれた回数:{agent.N[2]}回, 3が選ばれた回数:{agent.N[3]}回')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syumi-note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf02f90440595f5968a48e039387c923c9e6f6584bb1d7920e7063fafb8317aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

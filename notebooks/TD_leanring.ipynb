{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD学習について\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は強化学習の１種のアルゴリズムであるTD(λ)学習について説明していきます．\n",
    "\n",
    "$\\hat{V}\\left(s_t\\right)$をtステップ目の推定価値関数とします．\n",
    "\n",
    "### TD(0)法\n",
    "\n",
    "TD誤差を次のように設定し，$\\delta:=r_t+\\gamma \\hat{V}\\left(s_{t+1}\\right)-\\hat{V}\\left(s_t\\right)$を使い,$\\hat{V}\\left(s_t\\right)$が次のように更新していきます．\n",
    "\n",
    "$$\n",
    "\\hat{V}\\left(s_t\\right):=\\hat{V}\\left(s_t\\right)+\\alpha_t \\delta\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これをTD(0)法またはTD法と言います．\n",
    "\n",
    "ここからはTD法を一般化したTD(λ)法を解説します．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD(λ)法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の例では1ステップ先での予測誤差を使っていますね．\n",
    "\n",
    "ここでnステップ先の予測価値を使ってみましょう．\n",
    "\n",
    "$$\n",
    "c_t^{(n)} \\triangleq r_t+\\gamma r_{t+1}+\\cdots+\\gamma^n \\hat{V}\\left(s_{t+n}\\right)\n",
    "$$\n",
    "\n",
    "上はtからnステップ先の予測価値ですね．\n",
    "\n",
    "この時のTD誤差は次のようになります．\n",
    "$$\n",
    "\\delta_t^{(n)} \\triangleq c_t^{(n)}-\\hat{V}\\left(s_t\\right)=c_t^{(n)}-c_t^{(0)}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでさらに一般化して複数ステップでの予測価値を使っていきます．\n",
    "\n",
    "どれほど，長期のステップを重要視するかを調整する新しい割引変数λを導入します．\n",
    "\n",
    "$$\n",
    "c_{t, \\lambda} \\triangleq \\begin{cases}(1-\\lambda) \\sum_{n=1}^{\\infty} \\lambda^{n-1} c_t^{(n)} & (\\lambda \\in[0,1)) \\\\ c_t^{(\\infty)} & (\\lambda=1)\\end{cases}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように書くと，TD誤差は次のように書けます．\n",
    "\n",
    "$$\n",
    "\\delta_{t, \\lambda} \\triangleq c_{t, \\lambda}-\\hat{V}\\left(s_t\\right)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは**前方観測的なTD(λ)誤差**と言います．\n",
    "\n",
    "λが1に近ければ近いほど，モンテカルロ推定に近くなり，実際の観測する報酬と近いので推定の偏りは小さくなる一方で，推定の分散が大きくなることが知られています．\n",
    "\n",
    "上のTD誤差を使い，新しく予測価値関数の更新則を書き直すと，\n",
    "$$\n",
    "\\hat{V}\\left(s_t\\right):=\\hat{V}\\left(s_t\\right)+\\alpha_t \\delta_{t, \\lambda}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかしながら，式を見て分かるように，TD誤差を求めるのに，未来の価値まで観測してから更新しなければならないので，計算に大きなコストが発生しますね，\n",
    "\n",
    "このことからオンライン学習には適していません．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この考えをもう少し，オンライン学習に適した形にしてみましょう.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_t \\lambda & (1-\\lambda)\\left(\\sum_{n=1}^{\\infty} \\lambda^{n-1} r_t+\\gamma \\sum_{n=2}^{\\infty} \\lambda^{n-1} r_{t+1}+\\gamma^2 \\sum_{n=3}^{\\infty} \\lambda^{n-1} r_{t+2}+\\cdots\\right) \\\\\n",
    "& +(1-\\lambda)\\left(\\gamma \\hat{V}\\left(s_{t+1}\\right)+\\lambda \\gamma^2 \\hat{V}\\left(s_{t+2}\\right)+\\lambda^2 \\gamma^3 \\hat{V}\\left(s_{t+3}\\right)+\\cdots\\right)-\\hat{V}\\left(s_t\\right) \\\\\n",
    "= & r_t+\\lambda \\gamma r_{t+1}+\\lambda^2 \\gamma^2 r_{t+2}+\\cdots \\\\\n",
    "& +(1-\\lambda)\\left(\\gamma \\hat{V}\\left(s_{t+1}\\right)+\\lambda \\gamma^2 \\hat{V}\\left(s_{t+2}\\right)+\\lambda^2 \\gamma^3 \\hat{V}\\left(s_{t+3}\\right)+\\cdots\\right)-\\hat{V}\\left(s_t\\right) \\\\\n",
    "= & \\left(r_t+\\gamma \\hat{V}\\left(s_{t+1}\\right)-\\hat{V}\\left(s_t\\right)\\right) \\\\\n",
    "& +\\lambda \\gamma\\left(r_{t+1}+\\gamma \\hat{V}\\left(s_{t+2}\\right)-\\hat{V}\\left(s_{t+1}\\right)\\right) \\\\\n",
    "& +\\lambda^2 \\gamma^2\\left(r_{t+2}+\\gamma \\hat{V}\\left(s_{t+3}\\right)-\\hat{V}\\left(s_{t+2}\\right)\\right)+\\cdots\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の式をシグマ和を使って書き直すと，\n",
    "$$\n",
    "\\delta_{t, \\lambda}=\\sum_{n=0}^{\\infty}(\\lambda \\gamma)^n \\delta_{t+n}\n",
    "$$\n",
    "\n",
    "これを任意の時間Tステップ時までと，それ以降のTD誤差に分解すると，\n",
    "\n",
    "$$\n",
    "\\delta_{t, \\lambda}=\\sum_{\\tau=t}^T(\\lambda \\gamma)^{\\tau-t} \\delta_\\tau+\\sum_{\\tau=T+1}^{\\infty}(\\lambda \\gamma)^{\\tau-t} \\delta_\\tau\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "右辺の第2項は計算できないですが，第1項目は計算できますね．\n",
    "\n",
    "ここで各状態のトータルの更新量を考えます．\n",
    "\n",
    "ある特定の状態sについて，Tステップまでにsを訪問した時間ステップの集合を$\\mathcal{T}_s \\triangleq\\left\\{t_1, t_2, \\ldots, t_n\\right\\}$とすると，ステップTまでのTD(λ)の誤差の和は次のようになります．\n",
    "\n",
    "$$\n",
    "\\Delta_T(s) \\triangleq \\delta_{t_1, \\lambda}+\\delta_{t_2, \\lambda}+\\cdots+\\delta_{t_n, \\lambda}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにすると計算可能な誤差項は次のようになります．\n",
    "\n",
    "$$\n",
    "\\Delta_T^{\\text {past }}(s) \\triangleq \\sum_{\\tau=t_1}^T(\\lambda \\gamma)^{\\tau-t_1} \\delta_\\tau+\\sum_{\\tau=t_2}^T(\\lambda \\gamma)^{\\tau-t_2} \\delta_\\tau+\\cdots+\\sum_{\\tau=t_n}^T(\\lambda \\gamma)^{\\tau-t_n} \\delta_\\tau\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

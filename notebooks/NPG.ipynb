{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Policy Gradient (NPG)\n",
    "\n",
    "---\n",
    "\n",
    "今回はNPGの解説を行います．\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず，以下の最適化問題について考えます．\n",
    "\n",
    "$$\n",
    "V^\\pi(\\rho):=\\mathbb{E}_{x_0 \\sim \\rho}\\left[V^\\pi\\left(s_0\\right)\\right],\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\max _{\\theta \\in \\Theta} V^{\\pi_\\theta}(\\rho) \\text {. }\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで$\\rho$は初期状態分布です．\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "つまり，上の最適化問題の式がconcaveなら，微分して最大化できるパラメータを求めれば良いとなりますね．\n",
    "\n",
    "なので，まずは価値関数の微分を考えていきます．\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず，履歴$\\tau$を考えます．\n",
    "\n",
    "その履歴に沿った，方策と確率遷移の同時確率の記法を以下に示します．\n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}_\\mu^\\pi(\\tau)=\\mu\\left(s_0\\right) \\pi\\left(a_0 \\mid s_0\\right) P\\left(s_1 \\mid s_0, a_0\\right) \\pi\\left(a_1 \\mid s_1\\right) \\cdots\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "割引総報酬和を次のように定義します．\n",
    "\n",
    "$$\n",
    "R(\\tau):=\\sum_{t=0}^{\\infty} \\gamma^t r\\left(s_t, a_t\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "V^{\\pi \\theta}(\\mu)=\\mathbb{E}_{\\tau \\sim \\operatorname{Pr}_\\mu^{\\pi_\\theta}}^{\\pi_\\theta}[R(\\tau)] .\n",
    "$$\n",
    "\n",
    "しかしながら，方策で決定的な場合，微分不可になってしまうので，次のように変換して考えます．\n",
    "\n",
    "$$\n",
    "\\pi_\\theta(a \\mid s)=\\frac{\\exp \\left(\\theta_{s, a}\\right)}{\\sum_{a^{\\prime}} \\exp \\left(\\theta_{s, a^{\\prime}}\\right)},\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでなぜNPGを使わなきゃいけないかというと，価値関数がConvex関数にならないようなMDPが存在するためです．\n",
    "\n",
    "NPGはその凸性を確認しなくてもいいので，便利ですね．\n",
    "\n",
    "しかしながら，上の価値関数の定義からわかるように，モンテカルロのような推定をしていますね．\n",
    "\n",
    "その理由は．勾配を計算するのが難しくなってしまうからです．(勾配方向がわからなくなってしまうため)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAB8CAIAAAC5eN8NAAAKq2lDQ1BJQ0MgUHJvZmlsZQAASImVlwdUU+kSgP9700NCSwhFSuhNkE4AKSG00KWDjZAECCXEQBCxI4srqCgiIqAoukpRcC2ArBVRLCwCCnYXZBFR1sWCDZV3gUPY3Xfee+fNOXPmy2T+mfn/c/975gJAlueIRCmwPACpwgxxiLc7PSo6ho4bBjBQBkRgATAcbrqIGRzsDxCZtX+XD30AmrJ3zKZy/fv//1UUePx0LgBQMMJxvHRuKsKnEX3JFYkzAEAdQPy6KzNEU9yGMFWMNIjw/SlOmOHRKY6bZjSYjgkLYSFMBQBP4nDECQCQ6IifnslNQPKQ3BC2EPIEQoRFCLukpqbxED6BsBESg/hIU/kZcX/Jk/C3nHHSnBxOgpRn9jIteA9BuiiFs+r/PI7/LakpktkaBoiSEsU+IYhVRM7sfnKan5SFcYFBsyzgTcdPc6LEJ3yWuemsmFnmcTz8pGtTAv1nOV7gxZbmyWCHzTI/3TN0lsVpIdJa8WIWc5Y54rm6kuRwqT+Rz5bmz04Mi5zlTEFE4CynJ4f6zcWwpH6xJETaP1/o7T5X10u699T0v+xXwJauzUgM85HunTPXP1/InMuZHiXtjcf38JyLCZfGizLcpbVEKcHSeH6Kt9SfnhkqXZuBPJBza4OlZ5jE8Q2eZcACaSAFUTGgA3/klwcAGfysjKmNsNJEq8SChMQMOhO5YXw6W8g1n0+3srCyBmDqvs48Du9o0/cQot2c8+VsA8DZZnJy8tycz18OgNNID8TBOZ+RIwCyWQBc386ViDNnfNN3CYO8BeQAFagCTaALjIAZsAJ2wAm4AU/gC4JAGIgGywAXJIJUpPOVYA3YCPJAAdgBdoMyUAkOgWpwHJwETeAcuAyugVugC/SCR6AfDIFXYAx8ABMQBOEgMkSBVCEtSB8yhawgBuQCeUL+UAgUDcVCCZAQkkBroE1QAVQElUEHoRroZ+gsdBm6AXVDD6ABaAR6C32BUTAJpsIasAG8AGbATNgPDoOXwgnwCjgbzoW3w6VwFXwMboQvw7fgXrgffgWPowBKBkVDaaPMUAwUCxWEikHFo8Sodah8VAmqClWPakG1o+6g+lGjqM9oLJqCpqPN0E5oH3Q4motegV6H3oouQ1ejG9Ft6DvoAfQY+juGjFHHmGIcMWxMFCYBsxKThynBHMGcwVzF9GKGMB+wWCwNa4i1x/pgo7FJ2NXYrdh92AbsJWw3dhA7jsPhVHGmOGdcEI6Dy8Dl4fbijuEu4npwQ7hPeBm8Ft4K74WPwQvxOfgSfC3+Ar4HP4yfIMgT9AmOhCACj7CKUEg4TGgh3CYMESaICkRDojMxjJhE3EgsJdYTrxIfE9/JyMjoyDjILJIRyGyQKZU5IXNdZkDmM0mRZEJikZaQJKTtpKOkS6QHpHdkMtmA7EaOIWeQt5NryFfIT8mfZCmy5rJsWZ7setly2UbZHtnXcgQ5fTmm3DK5bLkSuVNyt+VG5QnyBvIseY78Ovly+bPy9+THFSgKlgpBCqkKWxVqFW4ovFDEKRooeiryFHMVDyleURykoCi6FBaFS9lEOUy5ShmiYqmGVDY1iVpAPU7tpI4pKSrZKEUoZSmVK51X6qehaAY0Ni2FVkg7SeujfVHWUGYq85W3KNcr9yh/VJmn4qbCV8lXaVDpVfmiSlf1VE1W3anapPpEDa1morZIbaXafrWraqPzqPOc5nHn5c87Oe+hOqxuoh6ivlr9kHqH+riGpoa3hkhjr8YVjVFNmqabZpJmseYFzREtipaLlkCrWOui1ku6Ep1JT6GX0tvoY9rq2j7aEu2D2p3aEzqGOuE6OToNOk90iboM3XjdYt1W3TE9Lb0AvTV6dXoP9Qn6DP1E/T367fofDQwNIg02GzQZvDBUMWQbZhvWGT42Ihu5Gq0wqjK6a4w1ZhgnG+8z7jKBTWxNEk3KTW6bwqZ2pgLTfabd8zHzHeYL51fNv2dGMmOaZZrVmQ2Y08z9zXPMm8xfL9BbELNg54L2Bd8tbC1SLA5bPLJUtPS1zLFssXxrZWLFtSq3umtNtvayXm/dbP3GxtSGb7Pf5r4txTbAdrNtq+03O3s7sV293Yi9nn2sfYX9PQaVEczYyrjugHFwd1jvcM7hs6OdY4bjScc/ncyckp1qnV4sNFzIX3h44aCzjjPH+aBzvwvdJdblgEu/q7Yrx7XK9ZmbrhvP7YjbMNOYmcQ8xnztbuEudj/j/pHlyFrLuuSB8vD2yPfo9FT0DPcs83zqpeOV4FXnNeZt673a+5IPxsfPZ6fPPbYGm8uuYY/52vuu9W3zI/mF+pX5PfM38Rf7twTAAb4BuwIeB+oHCgObgkAQO2hX0JNgw+AVwb8swi4KXlS+6HmIZciakPZQSujy0NrQD2HuYYVhj8KNwiXhrRFyEUsiaiI+RnpEFkX2Ry2IWht1K1otWhDdHIOLiYg5EjO+2HPx7sVDS2yX5C3pW2q4NGvpjWVqy1KWnV8ut5yz/FQsJjYytjb2KyeIU8UZj2PHVcSNcVncPdxXPDdeMW+E78wv4g/HO8cXxb9IcE7YlTCS6JpYkjgqYAnKBG+SfJIqkz4mByUfTZ5MiUxpSMWnxqaeFSoKk4VtaZppWWndIlNRnqh/heOK3SvGxH7iI+lQ+tL05gwqMhh1SIwkP0gGMl0yyzM/rYxYeSpLIUuY1bHKZNWWVcPZXtk/rUav5q5uXaO9ZuOagbXMtQfXQevi1rWu112fu35og/eG6o3Ejckbf82xyCnKeb8pclNLrkbuhtzBH7x/qMuTzRPn3dvstLnyR/SPgh87t1hv2bvlez4v/2aBRUFJwdet3K03t1luK902uT1+e2ehXeH+Hdgdwh19O113VhcpFGUXDe4K2NVYTC/OL36/e/nuGyU2JZV7iHske/pL/Uub9+rt3bH3a1liWW+5e3lDhXrFloqP+3j7eva77a+v1KgsqPxyQHDg/kHvg41VBlUlh7CHMg89PxxxuP0nxk81R9SOFBz5dlR4tL86pLqtxr6mpla9trAOrpPUjRxbcqzruMfx5nqz+oMNtIaCE+CE5MTLn2N/7jvpd7L1FONU/Wn90xVnKGfyG6HGVY1jTYlN/c3Rzd1nfc+2tji1nPnF/Jej57TPlZ9XOl94gXgh98LkxeyL45dEl0YvJ1webF3e+uhK1JW7bYvaOq/6Xb1+zevalXZm+8XrztfP3XC8cfYm42bTLbtbjR22HWd+tf31TKddZ+Nt+9vNXQ5dLd0Luy/0uPZcvuNx59pd9t1bvYG93X3hfffvLbnXf593/8WDlAdvHmY+nHi04THmcf4T+SclT9WfVv1m/FtDv13/+QGPgY5noc8eDXIHX/2e/vvXodzn5Oclw1rDNS+sXpwb8Rrpern45dAr0auJ0bw/FP6oeG30+vSfbn92jEWNDb0Rv5l8u/Wd6ruj723et44Hjz/9kPph4mP+J9VP1Z8Zn9u/RH4Znlj5Ffe19Jvxt5bvft8fT6ZOToo4Ys70KIBCFI6PB+DtUQDI0QBQupD5YfHMPD0t0Mw3wDSB/8QzM/e02AFQj5ipsYh1CYATiBogSt4AwNRIFOYGYGtrqc7OvtNz+pRgkS+WA85T1KvC2wD+ITMz/F/6/qcFU1ltwD/tvwC1+gXdVYw0tgAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAABVKADAAQAAAABAAAAfAAAAACKQz1eAAAhhElEQVR4Ae2deZyNZf/HzzTWJ0/C2CJJxFQkFbKMSkSypkWExCT70hgMRpns6VHZstRjf0R2oQiRH9W8ZCd+tgdj/ZUok+H83jMXx5k559znvs+57nPuOec6f8zc57qv5fv9fL+f77Xd93Ui7Ha7TX0UAgqB8EPgjvBTWWmsEFAIpCOgyK/8QCEQpggo8oep4ZXaCgFFfuUDCoEwRUCRP0wNr9RWCCjyKx9QCIQpAor8YWp4pbZCQJFf+YBCIEwRUOQPU8MrtRUCivzKBxQCYYqAIn+YGl6prRBQ5Fc+oBAIUwQU+cPU8EpthYAiv/IBhUCYIqDIH6aGV2orBBT5lQ8oBMIUAUX+MDW8UlshoMivfEAhEKYIKPKHqeGV2goBRX7lAwqBMEVAkT9MDa/UVggo8isfUAiEKQKK/GFqeKW2QkCRX/mAQiBMEVDkD1PDK7UVAor8ygcUAmGKQI4w1VuprRAwF4E/TnzRq+3yu54rdC753LWouOlTauQzt0Hjtaue3zhmqoRCwAsCdtuGQQ1GR/We91HC+7UilvxeoHReLyWCcVuRPxioqzZDHIFjK8Z+tbfVq41y2Ww7kzdHP/HsPZE2W0ryZwNia0VHjNptEe0V+S1iCCVGCCHw9871a//ZoHbZSNvVE5u2n6laJfrA4dO2YlVihybVj7KOnor81rGFkiRUEIjMl79wkXtL5LXdOPjtut+K1imwecyCXdZTTi34Wc8mSqLsjkBkza5JJVskJvTPdzXHw2VKrZ4+r1b/xdZTSpHfejZREmV7BHJHvTl705s31UiyqjphQP7UnUs69p9UtFKZs4fOnHus/cqEJmqu490ds8FOlXclrJXjyvGvJk/desoWOSOxQufBTR8MOvci7Ha7tSCSLM3F3T3rVsz1rytjauWY3DD3whYHv+1cTnIToVcdO1W9Hu6SZ8SOUU0uTm5ZfEnZkytHpq9Xq09IIRDqnWDKkpFT87ZvW+0ftku7dxyxVa9S5qb57LaNcZVixvwUUtaUpYzbnaqMyq+sH/HI87G/XpPVkqoniAiEOvl/3Lim0JMNHs5jsx/auDGiWtW7Dh24kD7UOb/qg3HfnvrrRhCht27T7neqkPf0tmHjv7r0t3UlV5IZQSDUyX9X/tzF7nkALX/dsPpQdIsym0fMOXzDfmRZtxVF+ja/3whSYZTX/U5VWuoXQ+IqdWx/d6j7jFRL7969+5133nnooYciIiJeeOGFESNG/P7771Jb8L2yUDdk7S4TS24YmhjX6ZOU8lUubR+VXKx1uZQJnyzt9F4nCz1t4bv9TCmZsVO1n52qztMOi52qRxvX3zO166GX//P6vRGmNBmalUL1+vXr58+ff8GCBb/99lvXrl2///776OhoIoIVFA75BT9XkHnKcuaaC9dznt/06aLI+oMHvvdWjeKuuVRKJgTS/tz07/FbztpsZ36a+HXKa/GDBrRvWDDUe45MCBj+0r9//5kzZ65du/aRRx5xLjxnzpy4uDjXdOc8gbkOQ/vxlGW/AZ1qFg/xbQ65/pPjHzFvDRjw5vOFVMevC9jNmze7ZT6FW7du3b1799jYWF0VmZkpDHt+M+FUdSsEMhBgkg/Dme17woMMCQkJBAJPGQKQHoY9fwBQVU2ENQIrV65Efw3mcxfmT5gwIbgwKfIHF3/VeggiMHv2bLp9bcXo848ePRrclb+QHfYDK+urGODYsWPHjx93tUSlSpVYhiW9VMbHNUMYpgCUwIrtqJ07d7oi4ADt7rvvzrKO5Zo5bFPY1cPrcCttBBgagKf2AEG7Bj/vBv35Yj/lTy+Op+7atYtNFBwX0L/++msS2VApXbo0FzAciLlw/lDEMejasWPH6dOnixcvXrly5fvuu4/MFTM+IjQ4lwql6yygOYMg1Kxdu7arvp5Aw9HJD2yhDZorIK4pLPU99dRTXplPQTzNbYR1rdOklOza8+O7K1asAOiNGzfu27evYcOGQAl1featGCmICPLLL79s3boVEz766KMvvvhirVq1QsOnAQ3E0HHTpk0OBUWwyxj9eOmpXF0wfZxw/DiRl5iLHxN2ibl16tQBMWKBHgK41pndUyZNmgQU/PWqCLYYPnz4qlWrvOY0KwMv9mSjD042ceJEaAkcEJ5rPM8k+SEJtnFui9ZNasvUapn+MAt97bXXAA11UArVTGpRgIZpRFsYKJuC5jM+wMtHT3GwIlbqyWlSHptJ9UqvFqSE+/IXV8ahpTfhqUJn8tA6Iw5POa2WTmTs3LmzCJSBBw2gROtEHFq3GjgmyUPg0+8hmMYkMfRUG8y29chHHqDEe4iRBNRAct5VPDoxZEASPhb3ZmIlXshCRnx8fHD7XhE6QQxhgm5BV5tKTwF2wNdZrSK/R6DouIDSgkyD+UjFR3+M96ik7BtQneGJBZnmiEfMBWQrbaH6FPklGINegrgooa+4+sviNg3r943v/MZLzRskLb0uQTZRBSEAjmHs4HatzvoIkRhs+z1EunT88w5Pt+iV1Kl1i2avxG75w7kVf64JAQRNhnLmLdb4I57/ZfWTHyjAwf8Wfa7BisN+HBcEJfnHhV09Ktve3XDFnpY6qZ6t7qSDPkPlriCiMq4mBFhhFgDnkUT/mNOdQiLthv27Hg9F91uaarefnvSS7fn4k2meM/tyxxHZfSls7TKGyE/mIGpjOfJDJ2gvo+/KQPX09NZ5n2q/8y+7/eLPb5e1JWxL9+Jzy95t8Fq/Ia1qxwxceEHCSIDBP6wjCgTLkAI0cONChgxHljcqaXv/53Ss1nQqGp2wJr3SU9s7N643oF/bWg3fWH/G/1bo+RkCMEORJLP/EsmpQSxI66mL6Q+Z9eQ0KY+1Hu9lI5pYyO4626RyttbdneRj+2Hh2LQ6Hd/r99pv80dvkXCyQqNGjXhDk83zYD2t1apVK6ZIbLPLAc3dST5nUn+cN/96lW6JY+qdm/XvbX/Rnn8fHhDkWQNmTFgcu/tXmYVK89wEzz7oEYioR2Y9OU3KYy3y48SC+dK0dXeSz/Um068Mzrm0W9+kUn0nNiggpS1cGe7xdFDg+c9747iRNOYDh7uTfH7J3WTcr/HRn/dtN7fU4AHPSvnpOUIVYtMg/JdiBYtUojOWMUELLvktNOxnFCRv4HproHR939JmDRoNebdjtz7dqz79Upt34vczkc34nFve/+HoygtO3LiV1///kJDxfyBXs3EgWpQ9cr56bkbr2q3i4jt1T3jrmSdfad344103J/03Tv3UubKt1bzj/oN1qwaEFxO9WwnZ+z8W8TqTF4udGC64S8VWIb+gjYzFKq+u89fxhCq2uO+v2U+taRFl677uVjDwWlBXBuxK/xOwpWymzQFaa0weWOX+uCVEyjnNI0r2mC9hqeQ2nnAAJlhw3/S2iLqvMD26aGenexg0aBC2I3NAfN69OFYhP8u/LPK5l1Fy6g37nk/eeLZt/JBXn6wev/C85HVshEUXr7Ffik7QHgeSUpX3Sq4mz2r5QsuB/do+UfeV9SkSh0uiabFoKnsI410tM3IQ/bUVgfDkuf/+++UPdY3oYxXy48RBDIFGEPOeF8MHRh39C8vehbZADiImcdMCgvgrAop4HcVAfhPma8Ykt8SCnzjSgFfBQCQEPqxjcZaD4+1X8zSaP38+Lx2aV3+Aax44cOCsWbMC3KgZzbGMJ/p2jcoJEOwQydmd0WhG85Yl3udnkZxFfk05s9nN119/vUuXLpMnTzbPuuK9cfPqDzziIvrTE2T3Y0J4nXno0KEc5sWe34ULF65cuVKmTJkzZ85wwVD/+vXrvHgezDd5b5k2yO/zgw5nmxctWhR5QEfPW9C3JNf1H4awmOTYdxXx2HFMBS+ccwSASSMOfqGBo5r46BLUYCY2FJs1azZ+/Hg6GaKM3DfnAY3NKsc5E25BM+ncDrYtCWcDBgwwiIdVsuNpPO5x6tSpq1evDhky5NKlS2IBmHRhI7QjtJ04cQKQOUKmfPnyPCQSLOmDTH7Uxo+/++67P//8kwv/rY7XMt0CWXHIBwsqHDjlYLvYVnV2a+bnPGrCFF36ERQENbTzXyO3nsHZ7z179ixYsGDdunWlREy6KUguDvkADQ5BcoCG14KhAzQuAJn9ebIxXouJicF9ZUUfxGC6ZIVe0S3sGonQe9GiRZCZoI/8nIxUoEABQqTzeWfgRiygNzp79mzhwoVxOSrEXaOiol5++WWNys26ZWyJwITcYIFu/i9+sPTNAhhViXUjXFm/sGQWz1pSnHjBtfZqrZ6aMSqS6MnpWx64h7Sg51txUQrFxRsBaM1imyHQ8GMBGrZDGIr7KQwiIQCS+KNRUMqCA2ELbnPx4Ycf6sQBZceNGyfGWQziwDPAwltitR//83mZF5ZSFueTQlpqcwQRpDJEhiyWo6yp5EdOfzZHxTahLNIS6RCGYET89Qc0MKSSLEha+Ss8/+CDD6D9l19+Ce19EJUamOwwcCAK+FaDD42KIsEBGoVFpyG6L+wtPhAY7+GWzthJTrodOOanw7nChwDEFEOVi8ABB5DnlkLp/0Ul1CY9tPs2PHHQngtXxf1JQR4sgk0NWYTAwTtRbkEjnbv+iGRqWQwK52E+7NXpsZ7kWb16taiKUOIpj/T0QJNf9IdQQuxRZyEtX0VQEBmy3EV5h7tzi0jBxzWPRIxoToQAKK1hXW6RAZIjD/kRySEnwuAiomMkA8SQTjmv+iKMkAc54VgAZBDxhbY04h0iCWyRB5IDmjPCXIugwF0+5BQqeFU2YBkE8/k7cuRIKY1SlRhEBIz/gSO/8DwIoMeQDs+AVM5WF6/NCqchTEgB3WslCCC47bZFhCFUaUcHRxOCFcQIDVY4Msu6oFGohfCAD4DOeMpqwrUeYUGQcduiEEbnAAHhRcyyzijAwXx+ftdVd59TAC2Q/A8Q+TGbD54HFgwQKCiowtdixYrVqFEjwOQRtsQF6YLwQkcHhTxI4oMwuD6scBtKfPYbjYIsQTdv3hzhUUEjmxm3RMR3hkjY1AdhhAsRZM2Q01CdqDBq1ChG+9OmTTNUUE9mKmfxz6TKswgQCPLT80Bg/mZpW+dX0UuIvgvOsKuUmJhowI/lHeOFYejH0AVHJB5x4bMv+llcJ3RkAyhAK1GiRO/evQ2AZpd5jJcIdjgAABIICKBc6FfBkZNQQnGfMXfU4+cFM3xqMG9wLoYVrP+JPs9PaTWKm05+EbD9VEOEjwceeAC/YZhtxInlH+OFMAxAeFTLTy/ElekAxURGw0J+3mLoJEDDELopJ/8YLxHsypUr5ydoInz4WYk/kOJ76EI40w2mL60xpmD937z4ImQyl/z4tz99vjNsgv+GEXdzjBeePbheo9jEoR2eqdTqg/2XnVvRef3MM8906NBBZ2aNbIIS0FIjTzBuuTvG6/K6sXUbvzF0UPeaVStO2/OncbF69epVtWpV4+WylhD8pw/IeiMg3yEktDTS/fgo1rBhw2hI7ppCFlHMJT99jsSejU6MTxYFvHxd1jZKvHx+Y/u4CuWqLd23f//hn94ub0vYes3Oi/2VbO2WGfVjoj6DT8NhyIOgYmQkqzYPjRhMTl3aO2d0g+9+t6dD9Kit3aLj+w9dWhNb/KGE1bzKmzzwyTztJ1wzVidsoRugMzBWzENugiZzGf56uG9WMsaCkDyZY1YDTvWCGCN/Xvt3SpN8aSL56asZ1kp0a6rCgYwF3Q3dSzwx8kdAOzC6fo4mo3ZNbTc44wxPUm7snFGtuO1f+wy9mu6LDN5MRkQL4jjWjXRp64beU6fTwb/t13+ZUf2+ojPWz31r+Jqb+a5eGF3TFjP+FzfFtJLwBPxBK4fBe/T8dC0GC/mbnYdwAtPtC0FF52/M4Y2oaCL5pdsbvQyb3OMxXpf+O6ltrX5rThoBSwhgePThrQn6Q/oxiVHSW4Ne73s6xuuGffeENo0GGT0BRXQDXls1lMGMKKwtAC3yDC/r/NrZJN5loMGyv3kzf7PIT7iC/BKBEFUJk/s9erx0cnz7eqO2pKQu79f/O0PHeKGUGZGYgMJsQjpcUivkBKSPW7324foLKZv6Jv3HyDFedNFyu32hFz1BIEdMQgVZj/ToNM30jI/OzEazmXWYB0GrSZMmdGhyP7wR2bRpUwKwH9VeOTm5dUzid6cW9mr6RN/Rd0fl0l0XczDymvEKcJs2bax+jsWeCa88//7GPXPjGzz34vZcZXQ7Dn0XrwCacegIr0svXbpUt/X8zcireLyKW7NmzcwV2W17pvVu12fo8PiOvefuTn81QeaH3o7HNMRpNzLrFXUZjRY687Mk5q2HvHRiSs9WfYaOjO/yxuyD+k/SIwAHfrIntKar8bZ+ycB4aq+2vRM/6PdWrzm7dC8nYGPMwV+d8GajbHQDnu3lI1wO9U0aiDnqd77g2Zu5c+c6p2RcH1nWqEG7Xan2yyvjH2w16tx1+9Xdazs8ZruvUadpWy7sndm1SgFb7S5jN5/R7QuZWhCv+pgxbqIZ3QHcYNjhJXkvPWTKl32nF37nw8T4Z+3ffrX9pO76ec+cl6V1Z5eZkXDGG9qaNR5bHr/o/+JGDu1ZJ2rVilUXbmhmvn2TEQ3hUixi304NiSve/3ccDeCikAtcqXu+eatKROkXY6f/cHHfrG6PF4yI6frhlrOeOlReiQ8YaLly5frrLzc/VhJh+2l242dfGPC/MT/M6hd1hy33AxWKX7c9/fb4t2oUjK7xdMF8ttf79K1ZJMKhfOqRH3efd9IoJfmzAbG1oiNG7XZkcVywOcqJIHwcKRIvTCE/oxRCslcpcyaPbRrz8pv7Wv20qHWp88vjGraKG/nuq3VjJxy7plGWJ/w4AkVk4EwL8WM1Gvnl3uLkH+0KM7vCWQ27ZqmHmsXKX5Z06V+ZvAAao3HpNbutEPJrHPWRGS4dzMncBjWLQVPmZGnfAAofE9UR9zmix6Xq0i9+sXx+24p3/TCiUez84+m3T27bdsYWfX9eLtN+TU4u0a7WvZlKHZ7VaezWq7eTilWJHZpUP+p2QuYroltkZGTmNDnfTDnDD3twFIwXAYu9MWVz5PiZi1cOb1u78Lqthz6e+fL0Mx3u+fvu5rln7ukyuPLtSOmuIkzCKigHpLFOJqbi7nJJTvv55581/DijsQxX+OTfC1fiCgWOLWqdbteUzVN1CMIpQ2wjucuYenZM3XLD8nZMXvVh2ZwZGXZ+Xq1Gh9xJP23q9bgosH9kvYrjvh27wd7zIXc13EwDKGYuzMABLWAd5smTJz1HzKxwlRLMec6JOR9lZo6LekzFzXOAli1bckoanpaQkIBLcwhf5vaPrnixeuOHFl4bPalls8L7hmXcTCd82v0lvhwxYnnEjb0bb1RoXUH/slLm6m02Ig5d6ZEjR7LekPHdFPJ7FyxlRpuSH1/5/ofFE159o0Djp22X9+0/V/qxf9psOXIVvtP2Pyeu2iqnB07PH+y9b98+qDhlypQcOQKkBX7G+NyzUO5cwXNu3XdyF2k//KNCkQ1uMp9y0a+MmfhHZIMqjirKtxs5qeS55uUdCW4vmLYwYypUqNDixYuXL1/uNo/0xJSUFA91uoPLOHM4/fXAgQMemvA3OS0tLU+ePHga/sbBWy7V5S9brW7TSxvHDF9xYlfamyOalSLHwe2bLj75yvAhA+65wzb3pQHlqo0X7nll05Su036wR0Re2pOy9/vYdgvvsOW4o3HCjJZlNPo5TX9zEcdgglm08TIYu7t81cYVD20YP2rZ0R+vtFvwcvHLK4wJzsF1HI8nzsmTcoidnuY5no0O0/NahjtX0FNvRh66fXHEoJsShWM6dHBOznlnTNsezgkRxR/v2MY5we01iNGP0e0zFJ83b57bPNITAc3DFMMdXJ6Y41msevXqmXRQIm1yriRvlFA/3cyWLVtcpChQYfCcJZlS7bYdO7Y8WmPEPQzU/9izba+terebv8V5Z8zbX8S8Tea971ce/dhnXzTW7t5ErQSdiIiIIkWKZGpE0hdTyA89WPDTkjBPzR6LnbdMUs9WKLD95EWbLd+V//52c77kobzDk7AHtPcwVPZQ2O9kR+vuanJ1BXe5PKQx4TfpqF/nBulJcGW04GNqr+JolNU+Yo27M2pd4fLMHEd1mS/M1kLQXrSJp3ECd+b2s3xL+3PT9BGzkm25iv968Ox9uz/9YOX5nI/uWHfx6YYF78iS1enrleNfTZ669ZQtckZihc6Dmz6YhZP4uUlDGw2ZnMQzfsmCn5HNydxFurw7eNnA7sPffX15pQWdvExc2TpySAQ0jmuzL+iZ8WMjrWDXTz/Brt/PSFx6ME2zJFPxgOkC7QPDfDRGKX2gwZzPBqczJwXmHP9qTDpzTsIcrR0Tjhv2vJWgCbe+m84WYTDLkfua5XL8I+btYV8ftW+f0OHBIqVavD/30Pm/F/XRZD713VmqRd9hXx+2rxj3ngvzGWnee++9qampmu36ejPTrqK8Lzx6ZdIja+y0e9tsl6dG5prYsmZDLnOanG/YmHAppy6L1cKIhjcyzBBKTC35q6NyCccTsOXOIBxL6WhOWhZeIqJFb4/M+NicWT0/I3+THllbtmwZz8P5Guv8KiemM2ZMNDis3owHIv3SVlJhOk/OrvfvoUz3ohCLeSxaxxDGbtswqMHoqN7zPkp4v1bEkt8LlNYz3c7aKA3xeN+2bduy3jDzO8uNkN/zMpNfbZtFfqavR48eJVL6JZ1LYbHpGqyfc8L8YkTjIpdfCUxceUw1WBHNL9H1FTbplwvZgdP31PCxFWO/2tvq1UbsuO1M3hz9xLPpq3Faj9a4VYuVRWay/K6U27tmJNIckxrHUy3SmzCL/AiKydlVlitxUlIS9JNbp6HaWAGaOXOm3M6f+VHlypXNi2gEF7kCG0KMzPxyIVuMcnsC0Q3oWiL9e+f6tf9sULtspO3qiU3bz1StEn3g8Gmbl0drXHVkCMOok2cKAwYmzdGo+DE7V3n8TzGR/Owq0flLHO+xscfkhp+p4gKH9l95/TXQIgeHsunC8yqwlEUH/WW1cxLd+XXa0aNHa2fz5y7jxurVq7NrFTCvFdLCT/b5AI1hf4UKFfr16+ePFs5lsX5cXNyYMWOcEz1eR+bLX7jIvSXy2m4c/Hbdb0XrFNg8ZkH6YSDGPxxDxlM3/CyX8aKGS2AsjopbuHChrgBnuPqMAj6uFegrxqyMxR4payRUgrz8ZQGJ1X6qZVihb7FHn6yauVhxefzxxxn20zSN0rqU5UyqYgURRTQbl3AT0MSIib9cS6hRRxUYi/POOO+QtUyhKa3rKOc9C1N9Pt7z3czh6XiCq2feq2UbaWABDy3ED2wFAEMmNYgvxc08AWXW+/yO9ugk8W9Qc6T4cIEbwTfnd5tgI+Yn0WxvpiERazADzQmri0jkLI8PSlEEFajct7I+lHIOASYtIAupqBy7ABdxjamyaIvWsxjRBxUoQs3+e1RG04bJTymO1mTcwRk7vgmvsxSIMUsi0PhJHO3mTCc/zQtrQRhtUTzdFcynEtcMwptxKSgEFSUiRVWwnS6LDxeiZucwTHOMRHzmPxXCfElO7AqMVgqgwUlAo3U04qtWbiP3UApARKx0jMucxzXClM4pRqpPzytiigyZLx9bNHZQgzK2Rr2HLDlg6ERCju6G/2Yc2i/QAEbOC2LYz294GcXHUP5AkB+B6P/xNmYBhoQjM97ptbsQPocrw0YYhf/57BwUpDiViKq0BSY8IxuqIYAhveAA0tKK0YKGWvGa2aEpdAVnn6OzwF/QEr2oVkMvWiGe+qA7pkFO6teo3KvKUjKgAr+rR88sRjRS6nSuRPwugPjrnC79OkDkR24x/8d+OpkJsmTGUfRD7KAunBQeRidDcQ23pggZcH18lyKO8KHTw4RHUhCP12Mb8tMQrfjT++lpSH8eZ+qCG7RENoylATtFuIvKYk6HOiJ8oJ2edilOK7QF7DrzI5JvcVZP/T7k4URtEQI0XMuHainCVJ9hBX91eqBvrYhSgSM/7aGPsCK+guu49RUS8QkCPMYms88QYBXqwTtFBMFB+VAnX11TICSZNdxdG2J0gf98aM6tN6AFdBK0569bxbWbCMxdhBeUdoWIFIwiYOQvX0WY8Bk0ClKJoLSnSgRowmqe8gQGGddWHPyXKJhgfp8+fXx2e1c5NVIiuOewaGAuCGwYlc/GjRtpkS1uR7viiB62Unl4w4wdDuZRfGiOzSfp++psagqleAMUt3YoxX6nSGncuDHvtzg/Lu7IY+ULB2gIKf1RM3Y6CTdsaAMRwQW7CCjwft4NIyUmJoY9Y2uCxuCfiI8/89gfjPXHiIAMDt26dfv000951lO6c7qVLQjkd5bD2bFIx8bWNLOzzF6v8Qa6UEc2MwKNo/JQusjyFJD0QGMGVvCfBxnq16//8ccfN2vWzDfSckIvb+/wLAaV8GicjgeW5agSZPLLUULVohAIHgJ0YDz02aNHDyL+9u3b2drUGQLoJNauXXv+/HkGuQS+/fv3+zl8MIpBGJA/deeSjv0nFa1U5uyhM+cea78yoYmJjzUaxd+y+f848UWvtsvveq7QueRz16Lipk+pkc+yslpBMIYAgsbEgvXr1+fMmZNnAd0OXsjAMgGnQtHbM2QQIeOll14K/Jg35Ml/cXfPuhVz/evKmFo5JjfMvbDFwW87l7OCs1haBl6D6/VwlzwjdoxqcnFyy+JLyp5cOTL9ZRj18YIATzTDak7a57lmDvmH2CzuMu/jRANO4+FhR77yrg5xgW7/m2++4YwzXugKPO2FGqFOfg4LLDMt57b1n1f8K7lz1cej5qQlVY08v2n22M8+n3vmgXWrPisnjsT0YtQwu83perUbV1uaNrhK5NrYYr2KzNybVD/9Nbjxk2cumdr4S3v8I2EGiDF1HX17vnz5Ll++nDdvXsF2QgDzeU6d5RhFT+MCYy35mVtjJyAUbrn5ld7zGT+fkDyh4rPpv0WpPq4IuPuV3lPp2Xx5Hta1epViEQRCffp7V/7cxe55AC1/3bD6UHSLMptHzDmsdS6Un6E0NIrLew0uNPAIVS2yHBYYcmrW7jKxZO+hieeLX7xRvsql7aOSyw5qqyavXswcWbNrUskWiQn9813N8XCZUqunz6vVf7GXMup29kMg1Ml/R4Umi7+W/4Oh2c/QhiTOHfXm7E1v3iySZKioypx9EAj1Yb9bS1zfu2bUF+v+7797Pps4+4CbX19zWyjsEw2cRBz2WGUPAEJ9tT97WEFJqRAIAgJh2fMHAWfVpELAcggo8lvOJEoghUBgEFDkDwzOqhWFgOUQUOS3nEmUQAqBwCCgyB8YnFUrCgHLIaDIbzmTKIEUAoFBQJE/MDirVhQClkNAkd9yJlECKQQCg4Aif2BwVq0oBCyHgCK/5UyiBFIIBAYBRf7A4KxaUQhYDgFFfsuZRAmkEAgMAor8gcFZtaIQsBwCivyWM4kSSCEQGAT+Hyhr+yM7XnoJAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のようなMDPを考えます．\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "報酬は$s_{H+1}$ に到達した時だけ，発生するとします．\n",
    "\n",
    "この場合，各状態にパラメータを持つとすると最大で，$4^{|S|}$個もち，報酬が発生する確率が稀なため，十分な探索が必要になりかつ，勾配が小さいので，勾配消失の問題になりますね．\n",
    "\n",
    "単のPolicy Gradientの場合，勾配が不安定だと，更新が不安定になります．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のMDPでは探索が重要ですが，上で示した，ソフトマックスで方策を変換すると，決定的な方策に近づくように急激に更新してしまうため，学習の面ではあまり良くないですね．\n",
    "\n",
    "そこでNPGが考えられる前では，正則化項を入れるという考えになりました．\n",
    "\n",
    "正則化項を入れた新しい目的関数は次のようになります．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_\\lambda(\\theta) & :=V^{\\pi_\\theta}(\\mu)-\\lambda \\mathbb{E}_{\\boldsymbol{s} \\sim \\mathrm{Unif}_S}\\left[\\mathrm{KL}\\left(\\text { Unif }_{\\mathcal{A}}, \\pi_\\theta(\\cdot \\mid s)\\right)\\right] \\\\\n",
    "& =V^{\\pi_\\theta}(\\mu)+\\frac{\\lambda}{|\\mathcal{S}||\\mathcal{A}|} \\sum_{\\dot{s}, a} \\log \\pi_\\theta(a \\mid s)+\\lambda \\log |\\mathcal{A}|,\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにすると，パラメータの更新は次のようになります．\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)}=\\theta^{(t)}+\\eta \\nabla_\\theta L_\\lambda\\left(\\theta^{(t)}\\right) .\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL-距離関数で正則化するというアイデアを活かし，更新の安定性や，収束の速さのどを考慮した方法がNPGになります．\n",
    "\n",
    "以降に出てくるフィッシャー行列はKL-距離関数のテーラー展開の2次近似になります，\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィッシャー行列の定義は次のようになります．\n",
    "\n",
    "$$\n",
    "\\mathcal{F}_\\rho^\\theta:=\\mathbb{E}_{g \\sim d_\\rho^{\\pi_\\theta}} \\mathbb{E}_{a \\sim \\pi_\\theta(\\cdot \\mid s)}\\left[\\left(\\nabla \\log \\pi_\\theta(a \\mid s)\\right) \\nabla \\log \\pi_\\theta(a \\mid s)^{\\top}\\right]\n",
    "$$\n",
    "\n",
    "パラメータの更新則は次のようになります，\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)}=\\theta^{(t)}+\\eta F_\\rho\\left(\\theta^{(t)}\\right)^{\\dagger} \\nabla_\\theta V^{(t)}(\\rho)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィッシャー情報量の定義は\n",
    "$$\n",
    "\\mathcal{F}_\\rho^\\theta:=\\mathbb{E}_{s \\sim d_\\rho^{\\pi_\\theta}} \\mathbb{E}_{a \\sim \\pi_\\theta(\\cdot \\mid s)}\\left[\\left(\\nabla \\log \\pi_\\theta(a \\mid s)\\right) \\nabla \\log \\pi_\\theta(a \\mid s)^{\\top}\\right]\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のフィッシャー情報行列はMoore-Penrose擬似逆を使っています．\n",
    "\n",
    "これを使うことによって状態分布の影響を打ち消し，逆行列の計算が楽になります．\n",
    "\n",
    "逆行列の存在性の有無が確認しなくても良くなります．\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータの更新方法は次のように書き換えられて，方策は次のように変換されます．\n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)}=\\theta^{(t)}+\\frac{\\eta}{1-\\gamma} A^{(t)}+\\eta v \\quad \\text { かつ } \\quad \\pi^{(t+1)}(a \\mid s)=\\pi^{(t)}(a \\mid s) \\frac{\\exp \\left(\\eta A^{(t)}(s, a) /(1-\\gamma)\\right)}{Z_t(s)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**最適な価値関数の計算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDPの構築\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import NamedTuple,Optional\n",
    "np.random.seed(10)\n",
    "\n",
    "S = 5 # 状態数\n",
    "A = 3 # 行動数\n",
    "S_set = np.arange(S)\n",
    "A_set = np.arange(A)\n",
    "gamma = 0.9 # 割引率\n",
    "\n",
    "rew = np.random.randn(S,A) # 報酬\n",
    "rew = np.array(rew)\n",
    "\n",
    "P = np.random.rand(S,A,S) # 遷移確率\n",
    "P = P.reshape(S*A,S)\n",
    "P = P/np.sum(P,axis=1,keepdims=True) # 正規化\n",
    "P = P.reshape(S,A,S)\n",
    "np.testing.assert_allclose(P.sum(axis=-1), 1, atol=1e-6)\n",
    "\n",
    "class MDP(NamedTuple):\n",
    "    S_set: np.ndarray\n",
    "    A_set: np.ndarray\n",
    "    rew: np.ndarray\n",
    "    P: np.ndarray\n",
    "    gamma: float\n",
    "    H: int\n",
    "    optimal_V: Optional[np.ndarray] = None\n",
    "\n",
    "    @property\n",
    "    def S(self):\n",
    "        return len(self.S_set)\n",
    "\n",
    "    @property\n",
    "    def A(self):\n",
    "        return len(self.A_set)\n",
    "\n",
    "H = int (1/(1-gamma) + 100)\n",
    "mdp = MDP(S_set,A_set,rew,P,gamma,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(jax.jit,static_argnames=('S','A'))\n",
    "def _optimal_Q(S:int,A:int,mdp:MDP):\n",
    "    Q = jnp.zeros((S,A))\n",
    "\n",
    "    def backup(Q):\n",
    "        V = jnp.max(Q,axis=1)\n",
    "        return mdp.rew + mdp.gamma * jnp.dot(mdp.P,V)\n",
    "    \n",
    "    body_fn = lambda i,Q: backup(Q)\n",
    "    return jax.lax.fori_loop(0,mdp.H,body_fn,Q)\n",
    "\n",
    "compute_optimal_Q = lambda mdp : _optimal_Q(mdp.S,mdp.A,mdp)\n",
    "optimal_Q = compute_optimal_Q(mdp)\n",
    "optimal_V = np.max(optimal_Q,axis=1)\n",
    "mdp = mdp._replace(optimal_V=optimal_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit,static_argnames=('S','A'))\n",
    "def _comupute_policy_Q(S:int,A:int,mdp:MDP,policy:np.ndarray):\n",
    "    Q = jnp.zeros((S,A))\n",
    "    def backup(Q):\n",
    "        max_Q = (policy * Q).sum(axis=1)\n",
    "        next_v = mdp.P @ max_Q\n",
    "        return mdp.rew + mdp.gamma * next_v\n",
    "    body_fn = lambda i,Q:backup(Q)\n",
    "    return jax.lax.fori_loop(0,mdp.H,body_fn,Q)\n",
    "compute_policy_Q = lambda mdp,policy:_comupute_policy_Q(mdp.S,mdp.A,mdp,policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:20<00:00, 4808.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.9401793 7.8497214 7.780638 ]\n",
      " [7.6949606 7.931794  7.789324 ]\n",
      " [7.7100496 7.9122024 7.825548 ]\n",
      " [7.9252543 7.8050566 7.724204 ]\n",
      " [7.8208895 7.846544  8.025346 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from jax import grad\n",
    "from tqdm import tqdm\n",
    "def softmax(x):\n",
    "    e_x = jnp.exp(x - jnp.max(x))\n",
    "    return e_x / jnp.sum(e_x)\n",
    "\n",
    "def compute_policy(policy,advantage,learning_rate):\n",
    "    return policy * softmax(learning_rate * advantage/(1- mdp.gamma))\n",
    "\n",
    "\n",
    "def kl_divergence(p,q):\n",
    "    return jnp.sum(p * jnp.log(p/q))\n",
    "\n",
    "def natural_grad(advantage,learning_rate):\n",
    "\n",
    "\n",
    "    return  learning_rate * advantage / (1-mdp.gamma) + learning_rate * 0.1\n",
    "\n",
    "\n",
    "def natural_policy_gradient(learning_rate, num_iterations):\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    params = jax.random.normal(key, (mdp.S, mdp.A))\n",
    "    Q = np.zeros((mdp.S,mdp.A))\n",
    "    policy = np.zeros_like(Q)\n",
    "    advantage = np.zeros_like(Q)\n",
    "\n",
    "    for _ in tqdm(range(num_iterations)):\n",
    "\n",
    "        policy = compute_policy(policy, advantage, learning_rate) \n",
    "        max_Q = (policy * Q).sum(axis=1)\n",
    "        next_v = mdp.P @ max_Q\n",
    "        Q = mdp.rew + mdp.gamma * next_v\n",
    "\n",
    "        advantage = Q - Q.max(axis=1,keepdims=True)\n",
    "\n",
    "\n",
    "        natural_grads = natural_grad(advantage,learning_rate)\n",
    "        params += natural_grads\n",
    "\n",
    "        \n",
    "\n",
    "    return Q\n",
    "\n",
    "learning_rate = 0.8\n",
    "num_iterations = 100000\n",
    "\n",
    "Q = natural_policy_gradient(learning_rate, num_iterations)\n",
    "\n",
    "print(optimal_Q - Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[9.271766 , 8.565001 , 6.235238 ],\n",
       "       [7.686577 , 8.55313  , 7.069238 ],\n",
       "       [7.975561 , 8.020751 , 7.8298397],\n",
       "       [7.750654 , 8.238083 , 8.927241 ],\n",
       "       [6.855824 , 8.874818 , 8.253976 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.3315865 ,  0.715279  , -1.5454003 ],\n",
       "       [-0.00838385,  0.621336  , -0.72008556],\n",
       "       [ 0.26551157,  0.10854852,  0.00429143],\n",
       "       [-0.17460021,  0.4330262 ,  1.2030374 ],\n",
       "       [-0.96506566,  1.028274  ,  0.22863013]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syumi-note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サンプルベースのCMDPにおけるNatural Policy Gradient (モデルフリー)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from docplex.mp.model import Model\n",
    "\n",
    "# MDPの構築\n",
    "from typing import NamedTuple ,Optional\n",
    "np.random.seed(10)\n",
    "\n",
    "S = 20 # 状態数\n",
    "A = 10 # 行動数\n",
    "S_set = np.arange(S)\n",
    "A_set = np.arange(A)\n",
    "gamma = 0.9 # 割引率\n",
    "\n",
    "rew = np.random.uniform(0,1,size=(S,A)) # 報酬\n",
    "rew = np.array(rew)\n",
    "\n",
    "utility = np.random.uniform(0,1,size=(S,A))\n",
    "utility = np.array(utility)\n",
    "\n",
    "\n",
    "P = np.random.rand(S,A,S) # 遷移確率\n",
    "P = P.reshape(S*A,S)\n",
    "P = P/np.sum(P,axis=1,keepdims=True) # 正規化\n",
    "P = P.reshape(S,A,S)\n",
    "np.testing.assert_allclose(P.sum(axis=-1), 1, atol=1e-6)\n",
    "rho = np.ones(S) /S\n",
    "b = 3\n",
    "\n",
    "class CMDP(NamedTuple):\n",
    "    S_set: np.ndarray\n",
    "    A_set: np.ndarray\n",
    "    rew: np.ndarray\n",
    "    utility: np.ndarray\n",
    "    P: np.ndarray\n",
    "    gamma: float\n",
    "    H: int\n",
    "    rho : np.ndarray\n",
    "    b : int\n",
    "\n",
    "\n",
    "    optimal_V: Optional[np.ndarray] = None\n",
    "\n",
    "    @property\n",
    "    def S(self):\n",
    "        return len(self.S_set)\n",
    "\n",
    "    @property\n",
    "    def A(self):\n",
    "        return len(self.A_set)\n",
    "\n",
    "H = int (1/(1-gamma) + 100)\n",
    "cmdp = CMDP(S_set,A_set,rew,utility,P,gamma,H,rho,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_to_policy(theta: np.ndarray, cmdp: CMDP) -> np.ndarray:\n",
    "    \"\"\"θから方策を計算する\"\"\"\n",
    "    '''[pi_(s1,a1),pi_(s1,a2),pi_(s1,a3),...]'''\n",
    "    # ここを実装\n",
    "    s = cmdp.S\n",
    "    a = cmdp.A\n",
    "    policy = []\n",
    "    theta = theta - np.amax(theta)\n",
    "    for i in range(s):\n",
    "        norm = np.sum(np.exp(theta[a*i:a*(i+1)]))\n",
    "        for j in range(a*i,a*(i+1)):\n",
    "            policy.append(np.exp(theta[j])/norm)\n",
    "\n",
    "\n",
    "    return np.array(policy)\n",
    "\n",
    "def get_Pi(prob : np.ndarray,cmdp:CMDP) -> np.ndarray:\n",
    "\n",
    "    Pi = np.zeros((cmdp.S, cmdp.S * cmdp.A))\n",
    "    for i in range(cmdp.S):\n",
    "        Pi[i, i * cmdp.A:(i + 1) * cmdp.A] = prob[i * cmdp.A:(i + 1) * cmdp.A]\n",
    "\n",
    "    return Pi\n",
    "\n",
    "def V_from_Q(qvals:np.ndarray,prob:np.ndarray,rho:np.ndarray,cmdp:CMDP) -> np.ndarray:\n",
    "\n",
    "    V = np.zeros(cmdp.S)\n",
    "    for i in range(cmdp.S):\n",
    "        for j in range(cmdp.A):\n",
    "            V[i] += qvals[i*cmdp.A+j] * prob[i*cmdp.A+j]\n",
    "\n",
    "    v_rho = np.dot(V,rho)\n",
    "    return v_rho\n",
    "\n",
    "#価値関数の推定\n",
    "def Q_value_estimate(cmdp:CMDP,policy:np.ndarray,uti:np.ndarray,Ksample:int):\n",
    "    s,a = cmdp.S,cmdp.A\n",
    "    gamma = cmdp.gamma\n",
    "\n",
    "    q_estimate = np.zeros((s,a))\n",
    "    policy = policy.reshape(s,a)\n",
    "\n",
    "    for _ in range(Ksample):\n",
    "        qest = np.zeros((s,a))\n",
    "        for i in range(s):\n",
    "            for j in range(a):\n",
    "                qest[i,j] = uti[i,j] #初期位置をs,aに設定してるため\n",
    "                length = np.random.geometric(p=1-gamma,size=1)\n",
    "                init_s = np.random.choice(cmdp.S_set,1,p=cmdp.P[i,j,:])\n",
    "                state = init_s[0]\n",
    "\n",
    "                for _ in range(length[0] - 1):\n",
    "                    action = np.random.choice(cmdp.A_set,1,p=policy[state])[0]\n",
    "                    qest[state,action] += uti[state,action]\n",
    "                    state = np.random.choice(cmdp.S_set,1,p=cmdp.P[state,action,:])[0]\n",
    "        q_estimate += qest\n",
    "\n",
    "    return q_estimate/Ksample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(scalar):\n",
    "    offset = 100\n",
    "    if scalar < 0:\n",
    "        scalar = 0\n",
    "    \n",
    "    if scalar > offset:\n",
    "        scalar = offset\n",
    "    \n",
    "    return scalar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適な価値関数を線形計画法で求める。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('CMDP')\n",
    "idx = [(i,j) for i in range(cmdp.S) for j in range(cmdp.A)]\n",
    "policy = model.continuous_var_dict(idx)\n",
    "\n",
    "for s in range(cmdp.S):\n",
    "    for a in range(cmdp.A):\n",
    "        model.add_constraint(policy[(s,a)] >= 0)\n",
    "        model.add_constraint(policy[(s,a)] <= 1)\n",
    "\n",
    "model.add_constraint(model.sum(policy[(s,a)] * cmdp.utility[s,a] / (1-gamma) for s in range(cmdp.S) for a in range(cmdp.A)) >= b)\n",
    "\n",
    "\n",
    "for s_next in range(cmdp.S):\n",
    "    model.add_constraint(\n",
    "        gamma * model.sum(policy[(s,a)] * cmdp.P[s,a,s_next] for s in range(cmdp.S) for a in range(cmdp.A)) \n",
    "        + (1 - cmdp.gamma) * cmdp.rho[s_next] == model.sum(policy[(s_next,a_next)] for a_next in range(cmdp.A))\n",
    "    )\n",
    "\n",
    "\n",
    "model.maximize(model.sum(policy[(s,a)] * cmdp.rew[s,a]/(1-gamma) for s in range(cmdp.S) for a in range(cmdp.A)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = model.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.552624829749226"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.get_objective_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/300 [00:04<23:20,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vioaltionしてる数は0\n",
      "最適な価値との差は-943.0450359018492\n",
      "最適な価値-943.0450359018489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/300 [00:27<22:03,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vioaltionしてる数は0\n",
      "最適な価値との差は-1611.323198949993\n",
      "最適な価値-1611.3231989499927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 11/300 [00:50<22:08,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vioaltionしてる数は0\n",
      "最適な価値との差は-1611.323199177711\n",
      "最適な価値-1611.323199177711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 16/300 [01:12<21:29,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vioaltionしてる数は0\n",
      "最適な価値との差は-1611.323199177711\n",
      "最適な価値-1611.323199177711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 17/300 [01:20<22:17,  4.72s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39m#advantage \u001b[39;00m\n\u001b[0;32m     38\u001b[0m adv \u001b[39m=\u001b[39m q_est \u001b[39m-\u001b[39m v_est\n\u001b[1;32m---> 40\u001b[0m qg_est \u001b[39m=\u001b[39m Q_value_estimate(cmdp,policy,cmdp\u001b[39m.\u001b[39;49mutility,K_samples)\n\u001b[0;32m     41\u001b[0m vg_est \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(S)\n\u001b[0;32m     42\u001b[0m vg_est \u001b[39m=\u001b[39m (policy \u001b[39m*\u001b[39m qg_est)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[34], line 53\u001b[0m, in \u001b[0;36mQ_value_estimate\u001b[1;34m(cmdp, policy, uti, Ksample)\u001b[0m\n\u001b[0;32m     50\u001b[0m state \u001b[39m=\u001b[39m init_s[\u001b[39m0\u001b[39m]\n\u001b[0;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m---> 53\u001b[0m     action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(cmdp\u001b[39m.\u001b[39;49mA_set,\u001b[39m1\u001b[39;49m,p\u001b[39m=\u001b[39;49mpolicy[state])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     54\u001b[0m     qest[state,action] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m uti[state,action]\n\u001b[0;32m     55\u001b[0m     state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(cmdp\u001b[39m.\u001b[39mS_set,\u001b[39m1\u001b[39m,p\u001b[39m=\u001b[39mcmdp\u001b[39m.\u001b[39mP[state,action,:])[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "N = 300\n",
    "theta = np.random.uniform(0,1,size=(cmdp.S*cmdp.A))\n",
    "dual = 0\n",
    "gap = []\n",
    "violation = []\n",
    "avg_gap = 0\n",
    "avg_violation = 0\n",
    "div_number = 0\n",
    "K_samples = 30\n",
    "step = 0.2\n",
    "dual_step = 0.2\n",
    "S = cmdp.S\n",
    "A = cmdp.A\n",
    "vio = 0\n",
    "for t in tqdm(range(N)):\n",
    "    policy = theta_to_policy(theta,cmdp)\n",
    "    Pi = get_Pi(policy,cmdp)\n",
    "    #逆行列から価値関数を求める。\n",
    "    P = cmdp.P.reshape(S*A,S)\n",
    "    mat = np.identity(S*A) - gamma * np.matmul(P,Pi)\n",
    "\n",
    "    #価値関数の計算\n",
    "    qr_val = np.matmul(np.linalg.inv(mat),cmdp.rew.reshape(S*A))\n",
    "    qr_val = qr_val.reshape(S,A)\n",
    "\n",
    "    qg_val = np.matmul(np.linalg.inv(mat),cmdp.utility.reshape(S*A))\n",
    "    qg_val = qg_val.reshape(S,A)\n",
    "\n",
    "    q_est = Q_value_estimate(cmdp,policy,cmdp.rew+dual*cmdp.utility,K_samples)\n",
    "    v_est = np.zeros(S)\n",
    "    \n",
    "    policy = policy.reshape(S,A)\n",
    "    v_est = (policy * q_est).sum(axis=1)\n",
    "    v_est = v_est.reshape(20,1)\n",
    "    v_est = np.tile(v_est,10) \n",
    "    #advantage \n",
    "    adv = q_est - v_est\n",
    "\n",
    "    qg_est = Q_value_estimate(cmdp,policy,cmdp.utility,K_samples)\n",
    "    vg_est = np.zeros(S)\n",
    "    vg_est = (policy * qg_est).sum(axis=1)\n",
    "    \n",
    "    vg_val = np.dot(vg_est.T,cmdp.rho)\n",
    "    # print(vg_val)\n",
    "    if vg_val < b:\n",
    "        vio += 1\n",
    "    # print(adv.shape)\n",
    "    theta = theta.reshape(S,A)\n",
    "\n",
    "    theta += step * adv/(1-cmdp.gamma)\n",
    "    theta = theta.reshape(S*A)\n",
    "    dual = proj(dual - dual_step * (vg_val-b))\n",
    "\n",
    "    if t % 5 == 0:\n",
    "        print(f'vioaltionしてる数は{vio}')\n",
    "        q = np.sum((policy * qr_val).sum())\n",
    "        q_dash = sum(policy[(s,a)] * qr_val[s,a]/(1-gamma) for s in range(cmdp.S) for a in range(cmdp.A))\n",
    "        gap.append(solution.get_objective_value() - q/(1-gamma))\n",
    "        print(f'最適な価値との差は{gap[-1]}')\n",
    "        print(f'最適な価値{solution.get_objective_value() - q_dash}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = v.reshape(20,1)\n",
    "v = np.tile(v,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7778335 , 0.7778335 , 0.7778335 , 0.7778335 , 0.7778335 ,\n",
       "        0.7778335 , 0.7778335 , 0.7778335 , 0.7778335 , 0.7778335 ],\n",
       "       [0.73388228, 0.73388228, 0.73388228, 0.73388228, 0.73388228,\n",
       "        0.73388228, 0.73388228, 0.73388228, 0.73388228, 0.73388228],\n",
       "       [0.89310588, 0.89310588, 0.89310588, 0.89310588, 0.89310588,\n",
       "        0.89310588, 0.89310588, 0.89310588, 0.89310588, 0.89310588],\n",
       "       [0.72414992, 0.72414992, 0.72414992, 0.72414992, 0.72414992,\n",
       "        0.72414992, 0.72414992, 0.72414992, 0.72414992, 0.72414992],\n",
       "       [0.00669741, 0.00669741, 0.00669741, 0.00669741, 0.00669741,\n",
       "        0.00669741, 0.00669741, 0.00669741, 0.00669741, 0.00669741],\n",
       "       [0.18333458, 0.18333458, 0.18333458, 0.18333458, 0.18333458,\n",
       "        0.18333458, 0.18333458, 0.18333458, 0.18333458, 0.18333458],\n",
       "       [0.77063825, 0.77063825, 0.77063825, 0.77063825, 0.77063825,\n",
       "        0.77063825, 0.77063825, 0.77063825, 0.77063825, 0.77063825],\n",
       "       [0.89934335, 0.89934335, 0.89934335, 0.89934335, 0.89934335,\n",
       "        0.89934335, 0.89934335, 0.89934335, 0.89934335, 0.89934335],\n",
       "       [0.29776818, 0.29776818, 0.29776818, 0.29776818, 0.29776818,\n",
       "        0.29776818, 0.29776818, 0.29776818, 0.29776818, 0.29776818],\n",
       "       [0.67535838, 0.67535838, 0.67535838, 0.67535838, 0.67535838,\n",
       "        0.67535838, 0.67535838, 0.67535838, 0.67535838, 0.67535838],\n",
       "       [0.33444287, 0.33444287, 0.33444287, 0.33444287, 0.33444287,\n",
       "        0.33444287, 0.33444287, 0.33444287, 0.33444287, 0.33444287],\n",
       "       [0.4589774 , 0.4589774 , 0.4589774 , 0.4589774 , 0.4589774 ,\n",
       "        0.4589774 , 0.4589774 , 0.4589774 , 0.4589774 , 0.4589774 ],\n",
       "       [0.27018121, 0.27018121, 0.27018121, 0.27018121, 0.27018121,\n",
       "        0.27018121, 0.27018121, 0.27018121, 0.27018121, 0.27018121],\n",
       "       [0.1088585 , 0.1088585 , 0.1088585 , 0.1088585 , 0.1088585 ,\n",
       "        0.1088585 , 0.1088585 , 0.1088585 , 0.1088585 , 0.1088585 ],\n",
       "       [0.37481726, 0.37481726, 0.37481726, 0.37481726, 0.37481726,\n",
       "        0.37481726, 0.37481726, 0.37481726, 0.37481726, 0.37481726],\n",
       "       [0.18370638, 0.18370638, 0.18370638, 0.18370638, 0.18370638,\n",
       "        0.18370638, 0.18370638, 0.18370638, 0.18370638, 0.18370638],\n",
       "       [0.5580119 , 0.5580119 , 0.5580119 , 0.5580119 , 0.5580119 ,\n",
       "        0.5580119 , 0.5580119 , 0.5580119 , 0.5580119 , 0.5580119 ],\n",
       "       [0.82298507, 0.82298507, 0.82298507, 0.82298507, 0.82298507,\n",
       "        0.82298507, 0.82298507, 0.82298507, 0.82298507, 0.82298507],\n",
       "       [0.26594399, 0.26594399, 0.26594399, 0.26594399, 0.26594399,\n",
       "        0.26594399, 0.26594399, 0.26594399, 0.26594399, 0.26594399],\n",
       "       [0.98618213, 0.98618213, 0.98618213, 0.98618213, 0.98618213,\n",
       "        0.98618213, 0.98618213, 0.98618213, 0.98618213, 0.98618213]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ],\n",
       "       [0.71717967, 0.11696971, 0.35789644, 0.16072117, 0.60168587,\n",
       "        0.06927592, 0.10500928, 0.78794715, 0.70932358, 0.90797541],\n",
       "       [0.81023054, 0.09194707, 0.38310912, 0.4388835 , 0.99063364,\n",
       "        0.03733071, 0.00248129, 0.0309497 , 0.3711929 , 0.8826824 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.tile(v,10)\n",
    "a.reshape(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syumi-note",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
